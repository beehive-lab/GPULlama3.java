package org.beehive.gpullama3.core.model.tensor;

import jdk.incubator.vector.ByteVector;
import jdk.incubator.vector.FloatVector;
import jdk.incubator.vector.VectorOperators;
import jdk.incubator.vector.VectorSpecies;
import org.beehive.gpullama3.core.model.GGMLType;
import uk.ac.manchester.tornado.api.types.arrays.HalfFloatArray;
import uk.ac.manchester.tornado.api.types.arrays.Int8Array;

import java.lang.foreign.MemorySegment;
import java.nio.ByteOrder;

public class Q8_0QuantizedTensor extends FloatTensor {

    private final int size;
    private final HalfFloatArray scales;  // One per 32-element block
    private final Int8Array quants;       // Quantized int8 values
    private MemorySegment segment;

    public Q8_0QuantizedTensor(int size, HalfFloatArray scales, Int8Array quants, MemorySegment segment) {
        this.size = size;
        this.scales = scales;
        this.quants = quants;
        this.segment = segment;
    }

    /**
     * Returns the scale factors for GPU kernels.
     *
     * @return HalfFloatArray containing fp16 scale factors
     */
    public HalfFloatArray getScales() {
        return scales;
    }

    /**
     * Returns the quantized values for GPU kernels.
     *
     * @return Int8Array containing quantized int8 values
     */
    public Int8Array getQuants() {
        return quants;
    }

    @Override
    public int size() {
        return size;
    }

    @Override
    public GGMLType type() {
        return GGMLType.Q8_0;
    }

    @Override
    public MemorySegment asMemorySegment() {
        return segment;
    }

    /**
     * Dequantizes and returns a single float value.
     *
     * @param index Element index
     * @return Dequantized float value
     */
    @Override
    public float getFloat(int index) {
        assert 0 <= index && index < size;
        int blockIdx = index / GGMLType.Q8_0.getBlockSize();
        float scale = scales.get(blockIdx).getFloat32();
        byte quant = quants.get(index);
        return quant * scale;
    }

    @Override
    public void setFloat(int index, float value) {
        throw new UnsupportedOperationException("Q8_0 tensors are read-only");
    }

    @Override
    protected FloatVector getFloatVector(VectorSpecies<Float> species, int index) {
        throw new UnsupportedOperationException();
    }

    /**
     * Optimized dot product with vectorization support.
     */
    @Override
    public float dot(int thisOffset, FloatTensor that, int thatOffset, int size) {
        if (USE_VECTOR_API && that instanceof ArrayFloatTensor) {
            return vectorDot(this, thisOffset, (ArrayFloatTensor) that, thatOffset, size);
        } else {
            return FloatTensor.scalarDot(this, thisOffset, that, thatOffset, size);
        }
    }

    /**
     * Vectorized dot product implementation using Java Vector API.
     */
    private static float vectorDot(Q8_0QuantizedTensor thiz, int thisOffset,
                                   ArrayFloatTensor that, int thatOffset, int size) {
        float result = 0f;
        int j = 0;

        // Align to block boundaries
        assert Integer.bitCount(GGMLType.Q8_0.getBlockSize()) == 1;
        int alignmentBound = Math.min(size, -thisOffset & (GGMLType.Q8_0.getBlockSize() - 1));
        if (alignmentBound > 0) {
            result += FloatTensor.scalarDot(thiz, thisOffset, that, thatOffset, alignmentBound);
            j += alignmentBound;
        }
        assert (thisOffset + j) % GGMLType.Q8_0.getBlockSize() == 0;

        FloatVector val = FloatVector.zero(F_SPECIES);
        int blockIndex = (thisOffset + j) / GGMLType.Q8_0.getBlockSize();
        int upperBound = size / GGMLType.Q8_0.getBlockSize() * GGMLType.Q8_0.getBlockSize();

        MemorySegment quantsSegment = thiz.quants.getSegment();

        for (; j < upperBound; j += GGMLType.Q8_0.getBlockSize(), blockIndex++) {
            float scaleValue = thiz.scales.get(blockIndex).getFloat32();
            FloatVector wScale = FloatVector.broadcast(F_SPECIES, scaleValue);

            if (F_SPECIES.vectorBitSize() == 256) {
                ByteVector wBytes = ByteVector.fromMemorySegment(
                        ByteVector.SPECIES_256,
                        quantsSegment,
                        (thisOffset + j) * 1L,
                        ByteOrder.LITTLE_ENDIAN
                );

                var sum0 = that.getFloatVector(F_SPECIES, thatOffset + j + 0 * F_SPECIES.length())
                        .mul(wBytes.castShape(F_SPECIES, 0));
                var sum1 = that.getFloatVector(F_SPECIES, thatOffset + j + 1 * F_SPECIES.length())
                        .mul(wBytes.castShape(F_SPECIES, 1));
                var sum2 = that.getFloatVector(F_SPECIES, thatOffset + j + 2 * F_SPECIES.length())
                        .mul(wBytes.castShape(F_SPECIES, 2));
                var sum3 = that.getFloatVector(F_SPECIES, thatOffset + j + 3 * F_SPECIES.length())
                        .mul(wBytes.castShape(F_SPECIES, 3));

                val = sum0.add(sum1).add(sum2).add(sum3).fma(wScale, val);

            } else if (F_SPECIES.vectorBitSize() == 128) {
                for (int i = 0; i < 2; i++) {
                    ByteVector wBytes = ByteVector.fromMemorySegment(
                            ByteVector.SPECIES_128,
                            quantsSegment,
                            (thisOffset + j + i * 16) * 1L,
                            ByteOrder.LITTLE_ENDIAN
                    );

                    var sum0 = that.getFloatVector(F_SPECIES, thatOffset + j + i * 16 + 0 * F_SPECIES.length())
                            .mul(wBytes.castShape(F_SPECIES, 0));
                    var sum1 = that.getFloatVector(F_SPECIES, thatOffset + j + i * 16 + 1 * F_SPECIES.length())
                            .mul(wBytes.castShape(F_SPECIES, 1));
                    var sum2 = that.getFloatVector(F_SPECIES, thatOffset + j + i * 16 + 2 * F_SPECIES.length())
                            .mul(wBytes.castShape(F_SPECIES, 2));
                    var sum3 = that.getFloatVector(F_SPECIES, thatOffset + j + i * 16 + 3 * F_SPECIES.length())
                            .mul(wBytes.castShape(F_SPECIES, 3));

                    val = sum0.add(sum1).add(sum2).add(sum3).fma(wScale, val);
                }
            } else {
                throw new UnsupportedOperationException("Unsupported vector width: " + F_SPECIES);
            }
        }

        result += val.reduceLanes(VectorOperators.ADD);

        if (j < size) {
            result += FloatTensor.scalarDot(thiz, thisOffset + j, that, thatOffset + j, size - j);
        }

        return result;
    }
}
